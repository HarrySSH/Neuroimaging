{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jingjinglab/cw/miniconda3/envs/Harry_env/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import lazypredict\n",
    "import mat4py\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import os \n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## \n",
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "Connectomes = scipy.io.loadmat('../Cells2Connectomes/Connectomes.mat')\n",
    "Connectome_direct = Connectomes['C_dir']\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "Region volumes, in a 424 vector, to get connectivity density, divide\n",
    "% each row in connectomes by each entry in the vector to get density. Units\n",
    "% are in 200 micron per vertex voxels.\n",
    "\n",
    "'''\n",
    "\n",
    "CellType_volumn = mat4py.loadmat('../Cells2Connectomes/Regional_Volumes.mat')\n",
    "CellType_volumn = CellType_volumn['region_vols']\n",
    "Celltype_volumn =np.array([np.array(xi) for xi in CellType_volumn])\n",
    "Celltype_volumn.shape\n",
    "\n",
    "# Nomarlize by the entry\n",
    "\n",
    "Connectome_direct_density = Connectome_direct/Celltype_volumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cell_type = mat4py.loadmat('../Cells2Connectomes/CellType_Maps.mat')\n",
    "Cell_type = Cell_type['cellmaps']\n",
    "Celltype_mtx =np.array([np.array(xi) for xi in Cell_type])\n",
    "Celltype_mtx.shape\n",
    "\n",
    "# Important : normalizing via the columns\n",
    "\n",
    "Celltype_mtx_norm = Celltype_mtx / Celltype_mtx.max(axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Anno1                                   Anno2  \\\n",
      "0         Anterior amygdalar area               Basolat amygdalar nucleus   \n",
      "1       Central amygdalar nucleus  Cortical amygdalar area, anterior part   \n",
      "2  Intercalated amygdalar nucleus               Lateral amygdalar nucleus   \n",
      "3     Posterior amygdalar nucleus                 Piriform-amygdalar area   \n",
      "4                          Culmen                          Flocculus area   \n",
      "\n",
      "                                     Anno3  \n",
      "0                Basomed amygdalar nucleus  \n",
      "1  Cortical amygdalar area, posterior part  \n",
      "2                 Medial amygdalar nucleus  \n",
      "3                           Central lobule  \n",
      "4                              Nodulus (X)  \n",
      "(212, 3)\n"
     ]
    }
   ],
   "source": [
    "Region_maps = mat4py.loadmat('../Cells2Connectomes/Region_Names.mat')\n",
    "Region_maps = Region_maps['region_names']\n",
    "Regionmaps_df = pd.DataFrame(Region_maps,columns = ['Anno1','Anno2','Anno3'])\n",
    "print(Regionmaps_df.head())\n",
    "print(Regionmaps_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KF = KFold(n_splits=5, random_state=None, shuffle=False)\n",
    "KF.get_n_splits(list(range(0,424)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform the validation, iteration:1\n",
      "Build Training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Testing set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 8/42 [02:55<10:12, 18.01s/it]"
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "for train_index, test_index in KF.split(list(range(0,424))):\n",
    "    k = k +1\n",
    "    print('Perform the validation, iteration:'+str(k))\n",
    "    Targets_Train_set = Connectome_direct_density[:,train_index]\n",
    "    Targets_Train_set  = Targets_Train_set[train_index,:]\n",
    "    Targets_Test_set  = Connectome_direct_density[:,test_index]\n",
    "    Targets_Test_set   = Targets_Test_set[test_index,:]\n",
    "    \n",
    "    \n",
    "    Dataset_Train_set = Celltype_mtx_norm[train_index,:]\n",
    "    Dataset_Test_set  = Celltype_mtx_norm[test_index,:]\n",
    "    print('Build Training set')\n",
    "    Target_training = []\n",
    "    Dataset_Training = []\n",
    "    for i in range(Dataset_Train_set.shape[0]):\n",
    "        for j in range(Dataset_Train_set.shape[0]):\n",
    "            #print(i)\n",
    "            #print(j)\n",
    "            if i == j:\n",
    "                pass       \n",
    "            else:\n",
    "\n",
    "                #_Dataset_Training = np.concatenate((Dataset_Train_set[i,:],Dataset_Train_set[j,:]))\n",
    "                #Dataset_Training = np.stack((Dataset_Training,_Dataset_Training))\n",
    "                Dataset_Training.append(np.concatenate((Dataset_Train_set[i,:],Dataset_Train_set[j,:])))\n",
    "                Target_training.append(Targets_Train_set[i,j])\n",
    "    Dataset_Training = np.stack(Dataset_Training)\n",
    "    Target_training =np.array([np.array(xi) for xi in Target_training])   \n",
    "    \n",
    "    print('Build Testing set')\n",
    "    Target_Testing = []\n",
    "    Dataset_Testing = []\n",
    "    for i in range(Dataset_Test_set.shape[0]):\n",
    "        for j in range(Dataset_Test_set.shape[0]):\n",
    "            #print(i)\n",
    "            #print(j)\n",
    "            if i == j:\n",
    "                pass       \n",
    "            else:\n",
    "                #print(Dataset_Test_set[i,j])\n",
    "\n",
    "                #_Dataset_Training = np.concatenate((Dataset_Train_set[i,:],Dataset_Train_set[j,:]))\n",
    "                #Dataset_Training = np.stack((Dataset_Training,_Dataset_Training))\n",
    "                Dataset_Testing.append(np.concatenate((Dataset_Test_set[i,:],Dataset_Test_set[j,:])))\n",
    "                Target_Testing.append(Targets_Test_set[i,j])\n",
    "    Dataset_Testing = np.stack(Dataset_Testing)\n",
    "    Target_Testing =np.array([np.array(xi) for xi in Target_Testing])      \n",
    "         \n",
    "    reg = LazyRegressor(verbose=0, predictions=True,ignore_warnings=False, custom_metric=None)\n",
    "    models, predictions = reg.fit(Dataset_Training, Dataset_Testing, Target_training, Target_Testing)\n",
    "\n",
    "    print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 10/42 [05:34<24:32, 46.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GammaRegressor model failed to execute\n",
      "Some value(s) of y are out of the valid range for family GammaDistribution\n"
     ]
    }
   ],
   "source": [
    "reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)\n",
    "models, predictions = reg.fit(Dataset_Training, Dataset_Testing, Target_training, Target_Testing)\n",
    "\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
